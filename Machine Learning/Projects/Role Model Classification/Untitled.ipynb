{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the HAAR cascade algorithm to detect face. If we use the code mentioned in website it will show attribute error.\n",
    "#face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#eye_cascade = cv.CascadeClassifier('haarcascade_eye.xml')\n",
    "#error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
    "# Therefore use this to call the cascades.\n",
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_eye.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Code\n",
    "def get_required_image(image_path):\n",
    "    img = cv.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    gray_img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "    for x,y,w,h in faces:\n",
    "        roi_img = img[y:y+h, x:x+w]\n",
    "        roi_gray = gray_img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_img)\n",
    "        print(eyes)\n",
    "        if len(eyes)<2:\n",
    "            return None\n",
    "        else:\n",
    "            return roi_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_required_image(image_path):\n",
    "    img = cv.imread(image_path)\n",
    "    gray_img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    eye_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_eye.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "    for x,y,w,h in faces:\n",
    "        roi_img = img[y:y+h, x:x+w]\n",
    "        roi_gray = gray_img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    if len(eyes) >= 2:\n",
    "        return(roi_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sir Code\n",
    "def get_cropped_image_if_2_eyes(image_path):\n",
    "    img = cv.imread(image_path)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            return roi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = './DataSets/'\n",
    "path_to_cropped = './DataSets/cropped_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_dataset):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./DataSets/.ipynb_checkpoints',\n",
       " './DataSets/Bill Gates',\n",
       " './DataSets/Elon Musk',\n",
       " './DataSets/Jeff Bezos',\n",
       " './DataSets/Sundar Pichai']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(path_to_cropped):\n",
    "     shutil.rmtree(path_to_cropped)\n",
    "os.mkdir(path_to_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "[[27 55 25 25]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[47 31 20 20]\n",
      " [22 18 24 24]]\n",
      "Generating cropped images in folder:  ./DataSets/cropped_images/Elon Musk\n",
      "[[15 20 25 25]\n",
      " [47 24 22 22]]\n",
      "()\n",
      "()\n",
      "()\n",
      "[[ 9 13 22 22]]\n",
      "[[34 23 22 22]]\n",
      "[[40 18 22 22]\n",
      " [10 20 25 25]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[10 16 23 23]\n",
      " [40 20 22 22]]\n",
      "()\n",
      "()\n",
      "()\n",
      "[[12 21 24 24]\n",
      " [37 19 23 23]]\n",
      "[[16 20 23 23]]\n",
      "[[19 29 25 25]\n",
      " [53 28 25 25]]\n",
      "[[60 30 26 26]\n",
      " [20 31 26 26]\n",
      " [10 32 27 27]]\n",
      "()\n",
      "()\n",
      "[[43 19 25 25]\n",
      " [10 20 24 24]]\n",
      "Generating cropped images in folder:  ./DataSets/cropped_images/Jeff Bezos\n",
      "()\n",
      "()\n",
      "[[68 32 33 33]\n",
      " [21 40 25 25]]\n",
      "[[60 27 26 26]\n",
      " [23 31 25 25]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        roi_color = get_required_image(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cropped + celebrity_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \",cropped_folder)\n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name\n",
    "            cv.imwrite(cropped_file_path, roi_color)\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Elon Musk': ['./DataSets/cropped_images/Elon Musk\\\\Elon Musk1.png',\n",
       "  './DataSets/cropped_images/Elon Musk\\\\Elon Musk2.png',\n",
       "  './DataSets/cropped_images/Elon Musk\\\\Elon Musk3.png',\n",
       "  './DataSets/cropped_images/Elon Musk\\\\Elon Musk4.png',\n",
       "  './DataSets/cropped_images/Elon Musk\\\\Elon Musk5.png',\n",
       "  './DataSets/cropped_images/Elon Musk\\\\Elon Musk6.png',\n",
       "  './DataSets/cropped_images/Elon Musk\\\\Elon Musk7.png'],\n",
       " 'Jeff Bezos': ['./DataSets/cropped_images/Jeff Bezos\\\\Jeff Bezos1.png',\n",
       "  './DataSets/cropped_images/Jeff Bezos\\\\Jeff Bezos2.png',\n",
       "  './DataSets/cropped_images/Jeff Bezos\\\\Jeff Bezos3.png']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celebrity_file_names_dict = {}\n",
    "for img_dir in cropped_image_dirs:\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    file_list = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        file_list.append(entry.path)\n",
    "    celebrity_file_names_dict[celebrity_name] = file_list\n",
    "celebrity_file_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Elon Musk': 0, 'Jeff Bezos': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_names_dict.keys():\n",
    "    class_dict[celebrity_name] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt   \n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv.cvtColor( imArray,cv.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv.imread(training_image)\n",
    "        scalled_raw_img = cv.resize(img, (32, 32))\n",
    "        img_har = w2d(img,'db1',5)\n",
    "        scalled_img_har = cv.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[celebrity_name])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4096)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulkg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\kulkg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\kulkg\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'logisticregression__C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm         0.9   \n",
       "1        random_forest         0.9   \n",
       "2  logistic_regression         0.7   \n",
       "\n",
       "                                   best_params  \n",
       "0       {'svc__C': 1, 'svc__kernel': 'linear'}  \n",
       "1  {'randomforestclassifier__n_estimators': 1}  \n",
       "2                 {'logisticregression__C': 1}  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('./DataSets/Image2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "scalled_raw_img = cv.resize(image, (32, 32))\n",
    "img_har = w2d(img,'db1',5)\n",
    "scalled_img_har = cv.resize(img_har, (32, 32))\n",
    "combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "X.append(combined_img)\n",
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
