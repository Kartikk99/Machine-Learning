# -*- coding: utf-8 -*-
"""InceptionV3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o-0j6uWoP_u_OQGGzgJfX2aZa4bJbd2_
"""

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.2
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator
from tensorflow.keras.models import Sequential
import numpy as np
from matplotlib import pyplot as plt

# Resize the images mentioned in the application page

IMG_SIZE= [224,224]
train_path= '/content/drive/My Drive/Colab Notebooks/Cotton Classification/Data/train'
test_path= '/content/drive/My Drive/Colab Notebooks/Cotton Classification/Data/test'

# importing the Inception V3 library and downloading the weights.
inception= InceptionV3(weights= 'imagenet', include_top= False, input_shape= IMG_SIZE+[3])

for layers in inception.layers:
  layers.trainable= False

from glob import glob
# To get the number of output layers.
folders = glob('/content/drive/My Drive/Colab Notebooks/Cotton Classification/Data/train/*')

len(folders)

x= Flatten()(inception.output)

prediction= Dense(len(folders), activation= 'softmax')(x)

model= Model(inputs= inception.input, outputs= prediction)

model.summary()

model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics= ['accuracy'])

# Using image generator to import images from data sets.

train_datagen= ImageDataGenerator(rescale= 1./255, horizontal_flip= True, zoom_range= 0.2, shear_range= 0.2)

test_datagen= ImageDataGenerator(rescale= 1./255)

train_dataset= train_datagen.flow_from_directory(directory= '/content/drive/My Drive/Colab Notebooks/Cotton Classification/Data/train',
                                                 target_size= (224,224),
                                                 batch_size= 23,
                                                 class_mode= 'categorical')

test_dataset= test_datagen.flow_from_directory(directory= '/content/drive/My Drive/Colab Notebooks/Cotton Classification/Data/test',
                                                 target_size= (224,224),
                                                 batch_size= 23,
                                                 class_mode= 'categorical')

r= model.fit_generator(epochs= 10, steps_per_epoch= len(train_dataset), 
                       generator= train_dataset,
                       validation_data= test_dataset,
                       validation_steps= len(test_dataset))

# plot the loss
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

# plot the accuracy
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

model.save('model_inceptionV3.h5')

y_pred = model.predict(test_dataset)

import numpy as np
y_pred = np.argmax(y_pred, axis=1)
y_pred

